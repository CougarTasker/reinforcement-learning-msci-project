\documentclass[]{final_report}
\usepackage{graphicx}
\usepackage{hyperref}

\usepackage{longtable}
\usepackage[utf8]{inputenc}
\usepackage[TS1,T1]{fontenc}
\usepackage{array, booktabs}
\usepackage{graphicx}
\usepackage[x11names,table]{xcolor}

\newcommand{\foo}{\makebox[0pt]{\textbullet}\hskip-0.5pt\vrule width 1pt\hspace{\labelsep}}


\emergencystretch=0.1em
\hfuzz=0.2pt
\tolerance=10000

%%%%%%%%%%%%%%%%%%%%%%
%%% Input project details
\def\studentname{Cougar Tasker}
\def\reportyear{2023-24}
\def\projecttitle{Resourceful Robots}
\def\supervisorname{Dr. Anand Subramoney}
\def\degree{MSci (Hons) in Computer Science}
\def\fullOrHalfUnit{Full Unit} % indicate if you are doing the project as a Full Unit or Half Unit
\def\finalOrInterim{Project Plan} % indicate if this document is your Final Report or Interim Report

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%
%%% Declaration

\chapter*{Declaration}

This report has been prepared on the basis of my own work. Where other published and unpublished source materials have been used, these have been acknowledged.

\vskip3em

Word Count: 

\vskip3em

Student Name: \studentname

\vskip3em

Date of Submission: 

\vskip3em

Signature:

\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% Table of Contents
\tableofcontents\pdfbookmark[0]{Table of Contents}{toc}\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% Your Abstract here

\begin{abstract}

  Autonomous robots such as Boston-dynamic's Spot are increasing in prevalence across a wide range of fields\cite{hagele2016robots}. Furthermore, these robots are increasingly integral in modern society, taking on ever more advanced tasks\cite{zaouter2020autonomous}. As autonomous robots take on increasingly complex and resource-intensive tasks, optimising their resource consumption while meeting objectives becomes an increasingly significant challenge.
  These autonomous robots operate in diverse environments with varying objectives, so a singular algorithm will not perform optimally for all cases. 
  
  This project aims to explore how reinforcement learning can provide a solution for effectively prioritising these objectives and managing resources. Reinforcement Learning, a form of machine learning, involves an agent learning to make decisions through interactions with its environment. Its ability to handle delayed rewards sets it apart from other machine-learning approaches, making it particularly well-suited for addressing this problem. In this project, we will simulate the environment, initially using a grid world and later incorporating more advanced environments from OpenAI's gym library\cite{gym}.
  
  //todo add more detail about reinforment learning add more refrences -> refrence the sutton book! and the other one
  
  \section*{Motivations}
  \addcontentsline{toc}{section}{Motivations}

  My inspiration for studying this degree in artificial intelligence comes in large part from my belief that AI is becoming increasingly pivotal in shaping the future of technology and industry. For this purpose, this project presents an invaluable opportunity for my personal and professional growth. It is a fantastic platform to improve my comprehension of reinforcement learning while offering hands-on experience. 

  What is unique about this resource-gathering robot project is its structured progression of complexity, Starting from fundamental concepts and culminating in advanced techniques. This gradient makes the complex nature of reinforcement learning more approachable than it may be in industry. 
  
  This project interests me because of its generality and applicability to many different scenarios. Resource-gathering has the potential to incorporate many real-world constraints like energy, visibility and obstacles. I would like to see how this impacts different exploration strategies.
   
  Last year, I completed my year-long internship at Zing, a digital communications company that is progressively incorporating AI systems for its customers. This experience has demonstrated to me the value of understanding the internals of these AI systems. <<insert reference to the increased value of ai in business>>. Through this project, I aim to improve my understanding of autonomous agents' benefits, biases, and limitations. This knowledge will be desirable for many companies like Zing working with artificial agents.


  \section*{Objectives}
  \addcontentsline{toc}{section}{Objectives}

  The primary objective is to develop and understand reinforcement learning agents. The project will include two parts: a report and a graphical program. In the report, I will describe the reinforcement learning concepts that are implemented by the program, such as Markov decision processes and finding optimal policies by the Bellman equations. The report will also cover the software engineering process of the program and the results of different parameter choices and exploration strategies. The program will be developed in Python using the libraries Kivy for graphics and PyTorch for Deep Neural networks. The program should achieve the following goals:
  \begin{itemize}
    \item Energy-Efficient Navigation: Create a robot that can autonomously navigate a grid world while making optimal decisions to conserve energy. The robot should learn to prioritise energy-efficient paths.
    \item Resource Gathering Strategies: Design intelligent resource-gathering strategies for the robot, ensuring it collects essential resources while balancing energy expenditure. The robot should adapt its behaviour based on the availability of resources and its current energy levels.
    \item Dynamic Energy Management: The robot should monitor its energy reserves and adjust its actions accordingly. This includes learning when to engage in resource gathering and when to return to a charging station.
    \item Effective Exploration: Develop exploration strategies that enable the robot to learn and adapt to different grid world scenarios.
    \item Deep Reinforcement Learning: As an extension, the program should integrate deep neural networks (DNN) with Q-learning. The advantage of using a DNN instead of a table is the DNN's ability to generalise knowledge\cite{franccois2018introduction}. This unlocks working in environments with far more extensive observations and action spaces, allowing for added complexity to our existing environment or an extension of integrating a different environment, such as one from OpenAI's gym library\cite{gym}.
  \end{itemize}
  
  
  

\end{abstract}
\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% Project Spec

% \chapter*{Project Specification}
% \addcontentsline{toc}{chapter}{Project Specification}
% Your project specification goes here.

%%%%%%%%%%%%%%%%%%%%%%
%%% Timeline
\chapter{Timeline}

\section{Term One}

{
  \renewcommand{\arraystretch}{1.5}
  
\begin{longtable}{@{\,}p{.15\textwidth} <{\hskip 2pt} !{\foo} >{\raggedright\arraybackslash}p{.35\textwidth} p{.4\textwidth}}
\multicolumn{1}{@{\,}p{.15\textwidth}}{Week} & \multicolumn{1}{p{.35\textwidth}}{Goals} & \multicolumn{1}{p{.4\textwidth}}{Explanation/Motivation} \\
\hline
\endhead
% 18/09/2023-22/09/2023 & Study Reinforcement Learning: Reinforcement Learning in 'Machine Learning' by Tom Mitchell & This book has established a foundational understanding of reinforcement learning, which will serve as the basis for creating this project plan.\\
%  25/09/2023-29/09/2023 & Create first project plan draft & Creating a project plan draft enables my supervisor to review and guide the final report in the right direction.\\
%  02/10/2023-06/10/2023 & Complete project plan and its formatting & Incorporate enhancements suggested by my supervisor, refine document formatting to enhance its visual appeal, and gain proficiency in LaTeX for future reports.\\
%  09/10/2023-13/10/2023 & Research reinforcement learning: \begin{itemize}
%   \item Read the chapters 1,3,4 of Reinforcement Learning An Introduction second edition Richard S. Sutton and Andrew G. Barto
%   \item Create the first draft of Markov decision processes (MDPs) report
%   \item Create the first draft of policy and value function report 
% \end{itemize} & Starting with research on reinforcement learning provides a strong foundation for application development. Additionally, early report drafting allows for increased opportunity for feedback \\
%  16/10/2023-20/10/2023 & Research reinforcement learning: \begin{itemize}
%  \item Read the chapter 6 of Reinforcement Learning An Introduction second edition Richard S. Sutton and Andrew G. Barto
%  \item Create the first draft of Q-learning report
%  \item Create the first draft report about learning as incrementally optimising policy in an MDP \end{itemize} & This research helps deepen my understanding of reinforcement learning, and the reports serve the dual purpose of advancing toward the Interim submission while testing my knowledge.\\
% 23/10/2023-27/10/2023 & Initialise project: \begin{itemize}
%  \item development environment configuration
%  \item basic project configuration \end{itemize} & This setup will establish the essential groundwork for application development, ensuring the proper configuration of the environment and tools to facilitate the creation of a robust application while upholding high code standards and quality.\\
%  30/10/2023-03/11/2023 & model simple state and reward function for grid world. 
% provide basic visualisation for a grid world state. 
% mock the AI with hard-coded actions and visualise these actions being played out.  & The primary objective for this week is to create a vertical slice of the application, enabling rapid feedback and issue identification before committing to full-scale development.\\
% 06/11/2023-10/11/2023 & Implementation of value iteration algorithm & As a planning algorithm, implementing this algorithm will efficiently generate optimal policies for our environment and grid world, providing a benchmark for our Q-learning implementation and assisting in the debugging process.\\
% 13/11/2023-17/11/2023 & Implementation of Q-learning & The implementation of Q-learning will serve as an important focal point for the presentation. Initiating this process at an early stage will allow pleanty of time to ensure its completion.\\
% 20/11/2023-24/11/2023 & Finalise the report & As the Interim report deadline approaches, this week is dedicated to the finalization of the report, identifying errors, and making improvments wherever possible.\\
% 27/11/2023-01/12/2023 & \begin{itemize}
%   \item Prepare for the presentation
%   \item Improve project graphics, add controls
%   \item Submit the interim report
%   \end{itemize} 
%  & Improving the graphics will help make the main functionality clear and appealing, and adding controls will provide interactivity that will help the program come across well for the presentation. \\
% 04/12/2023-08/12/2023 & give the presentation  & \\
\end{longtable}

\section{Term Two}

\begin{longtable}{@{\,}p{.15\textwidth} <{\hskip 2pt} !{\foo} >{\raggedright\arraybackslash}p{.35\textwidth} p{.4\textwidth}}
  \multicolumn{1}{@{\,}p{.15\textwidth}}{Week} & \multicolumn{1}{p{.35\textwidth}}{Goals} & \multicolumn{1}{p{.4\textwidth}}{Explanation/Motivation} \\
  \hline
  \endhead
% 08/01/2024-12/01/2024 & Make the first draft of poster & As a precaution, given the absence of a specific deadline, I intend to start the poster at the start of the term.\\
% 15/01/2024-19/01/2024 & Develop different exploration strategies & The implementation of multiple exploration strategies is important for my final report, so, I am giving it a high priority.\\
% 22/01/2024-26/01/2024 & 
%  - Record data from different exploration strategies and parameter choices
%  - Analyse the exploration strategies' effectiveness & After creating the strategies, it is the ideal time to get their data and analyse it because I can iterate on the strategies to provide more in-depth research. However, I will need to be careful not to introduce data snooping.\\
%  29/01/2024-03/02/2024 & 
% write a report on the effect of different parameter choices and exploration strategies & Following the recent data analysis, the report's writing follows naturally and benefits from the insights gained.\\
% 05/02/2024-10/02/2024 & implement deep learning  & While a two-week timeline for implementing deep learning may be ambitious, leveraging the PyTorch library will simplify the process. The remaining tasks would include integrating the model with the existing codebase and fine-tuning the model\\
% 12/02/2024-17/02/2024 & implement deep learning  & \\
% 19/02/2024-24/02/2024 & Write the report on the software engineering process involved in generating this program & With the majority of development now complete, this is a good week to reflect on the whole engineering process and report on it.\\
% 26/02/2024-02/03/2024 & integrate agent with different environments from gym & As a further extension, it would be valuable to assess how well the agent generalises to entirely novel environments. However, if there are time constraints, this can be omitted without compromising the core objectives.\\
% 04/03/2024-09/03/2024 & Report on the data from deep learning and how the agent generalised to new environments & The results obtained from deep learning will help elevate the section on different learning strategies, offering an additional perspective from a different type of environment.\\
% 11/03/2024-16/03/2024 & improve and Finalise report & Given that the report accounts for 30% of the final grade, it is crucial to allocate time to enhance and refine it according to my supervisor's feedback.\\
% 18/03/2024-23/03/2024 & improve and Finalise report & \\
% 25/03/2024-30/03/2024 & submit report & \\
\end{longtable}
}



\chapter{Risks And Mitigations}

\section{Hardware Issues}

\begin{center}
    \begin{tabular}{l l}
    Likelihood: & Low \\
    Importance: & High \\
    \end{tabular}
  \end{center}

Hardware failures, such as a lost or malfunctioning laptop, could disrupt the project's progress. Project data should be regularly backed up externally to reduce this risk. The project will be stored under Git with a GitHub remote repository. Under this arrangement, frequent code pushes upstream can minimise potential data loss. The report will be written on the Google Docs platform, providing cloud backup and version control.


\section{Time Management Issues}

\begin{center}
    \begin{tabular}{l l  }
    Likelihood: & Moderate \\
    Importance: & Moderate \\
    \end{tabular}
  \end{center}

Underestimating the time required for tasks could result in missing milestones or goals. Perfect time estimates are impossible; however, tasks can subdivided appropriately to avoid significant surprises. Spreading out tasks evenly and leaving some buffer time can assist in avoiding work being cut short. 

\section{Machine Learning Risks}

\begin{center}
    \begin{tabular}{l l  }
    Likelihood: & Moderate \\
    Importance: & Low \\
    \end{tabular}
  \end{center}

Machine learning can be a slow and computationally expensive task; this risks slowing the development or failing to train an effective model. The Q-learning table's complexity and size can be gradually increased and dynamically controlled to avoid computational bottlenecks. Manual fine-tuning of the system can be timely. Instead, the hyperparameters will be optimised with grid search. 

\section{Software Development Challenges}

\begin{center}
    \begin{tabular}{l l  }
    Likelihood: & High \\
    Importance: & Moderate \\
    \end{tabular}
  \end{center}

Developing a complete graphical application can be complex, and unexpected software bugs may arise. Modern software engineering principles can minimise bugs and improve software quality. That is why this project will have version control, test-driven development, documentation, and static code analysis. 

\section{GUI Development Challenges}

\begin{center}
    \begin{tabular}{l l  }
    Likelihood: & Moderate \\
    Importance: & Low \\
    \end{tabular}
  \end{center}

Designing and implementing the Graphical User Interface may be more time-consuming or challenging than anticipated. This project will use GUI development libraries or frameworks that streamline the process. Start GUI development early in the project to allow for iterative improvements.

\section{Understanding of Reinforcement Concepts}

\begin{center}
    \begin{tabular}{l l  }
    Likelihood: & Moderate \\
    Importance: & High \\
    \end{tabular}
  \end{center}

Reinforcement learning has several abstract concepts, such as MDPs, Bellman equations, dynamic programming, or Q-learning, which may lead to incorrect implementations or interpretations. Referencing textbooks and research papers to check results can validate findings. Thoroughly studying reinforcement learning concepts can avoid misinterpretations.


%%%% ADD YOUR BIBLIOGRAPHY HERE
\newpage

\bibliographystyle{plain}
\bibliography{refrences}
\addcontentsline{toc}{chapter}{Bibliography}
\label{endpage}



\end{document}

\end{article}
