\documentclass[]{final_report}
\usepackage{graphicx}
\usepackage{hyperref}


%%%%%%%%%%%%%%%%%%%%%%
%%% Input project details
\def\studentname{Cougar Tasker}
\def\reportyear{2023-24}
\def\projecttitle{Resourceful Robots}
\def\supervisorname{Dr. Anand Subramoney}
\def\degree{MSci (Hons) in Computer Science}
\def\fullOrHalfUnit{Full Unit} % indicate if you are doing the project as a Full Unit or Half Unit
\def\finalOrInterim{Project Plan} % indicate if this document is your Final Report or Interim Report

\begin{document}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%
%%% Declaration

\chapter*{Declaration}

This report has been prepared on the basis of my own work. Where other published and unpublished source materials have been used, these have been acknowledged.

\vskip3em

Word Count: 

\vskip3em

Student Name: \studentname

\vskip3em

Date of Submission: 

\vskip3em

Signature:

\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% Table of Contents
\tableofcontents\pdfbookmark[0]{Table of Contents}{toc}\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% Your Abstract here

\begin{abstract}

  Autonomous robots such as Boston-dynamic's Spot are increasing in prevalence across a wide range of fields\cite{hagele2016robots}. Furthermore, these robots are increasingly integral in modern society, taking on ever more advanced tasks\cite{zaouter2020autonomous}. As autonomous robots take on increasingly complex and resource-intensive tasks, optimising their resource consumption while meeting objectives becomes an increasingly significant challenge.
  These autonomous robots operate in diverse environments with varying objectives, so a singular algorithm will not perform optimally for all cases. 
  
  This project aims to explore how reinforcement learning can provide a solution for effectively prioritising these objectives and managing resources. Reinforcement Learning, a form of machine learning, involves an agent learning to make decisions through interactions with its environment. Its ability to handle delayed rewards sets it apart from other machine-learning approaches, making it particularly well-suited for addressing this problem. In this project, we will simulate the environment, initially using a grid world and later incorporating more advanced environments from OpenAI's gym library\cite{gym}.
  
  //todo add more detail about reinforment learning add more refrences -> refrence the sutton book! and the other one
  
  \section*{Motivations}
  \addcontentsline{toc}{section}{Motivations}

  My inspiration for studying this degree in artificial intelligence comes in large part from my belief that AI is becoming increasingly pivotal in shaping the future of technology and industry. For this purpose, this project presents an invaluable opportunity for my personal and professional growth. It is a fantastic platform to improve my comprehension of reinforcement learning while offering hands-on experience. 

  What is unique about this resource-gathering robot project is its structured progression of complexity, Starting from fundamental concepts and culminating in advanced techniques. This gradient makes the complex nature of reinforcement learning more approachable than it may be in industry. 
  
  This project interests me because of its generality and applicability to many different scenarios. Resource-gathering has the potential to incorporate many real-world constraints like energy, visibility and obstacles. I would like to see how this impacts different exploration strategies.
   
  Last year, I completed my year-long internship at Zing, a digital communications company that is progressively incorporating AI systems for its customers. This experience has demonstrated to me the value of understanding the internals of these AI systems. <<insert reference to the increased value of ai in business>>. Through this project, I aim to improve my understanding of autonomous agents' benefits, biases, and limitations. This knowledge will be desirable for many companies like Zing working with artificial agents.


  \section*{Objectives}
  \addcontentsline{toc}{section}{Objectives}

  The primary objective is to develop and understand reinforcement learning agents. The project will include two parts: a report and a graphical program. In the report, I will describe the reinforcement learning concepts that are implemented by the program, such as Markov decision processes and finding optimal policies by the Bellman equations. The report will also cover the software engineering process of the program and the results of different parameter choices and exploration strategies. The program will be developed in Python using the libraries Kivy for graphics and PyTorch for Deep Neural networks. The program should achieve the following goals:
  \begin{itemize}
    \item Energy-Efficient Navigation: Create a robot that can autonomously navigate a grid world while making optimal decisions to conserve energy. The robot should learn to prioritise energy-efficient paths.
    \item Resource Gathering Strategies: Design intelligent resource-gathering strategies for the robot, ensuring it collects essential resources while balancing energy expenditure. The robot should adapt its behaviour based on the availability of resources and its current energy levels.
    \item Dynamic Energy Management: The robot should monitor its energy reserves and adjust its actions accordingly. This includes learning when to engage in resource gathering and when to return to a charging station.
    \item Effective Exploration: Develop exploration strategies that enable the robot to learn and adapt to different grid world scenarios.
    \item Deep Reinforcement Learning: As an extension, the program should integrate deep neural networks (DNN) with Q-learning. The advantage of using a DNN instead of a table is the DNN's ability to generalise knowledge\cite{franccois2018introduction}. This unlocks working in environments with far more extensive observations and action spaces, allowing for added complexity to our existing environment or an extension of integrating a different environment, such as one from OpenAI's gym library\cite{gym}.
  \end{itemize}
  
  
  

\end{abstract}
\newpage

%%%%%%%%%%%%%%%%%%%%%%
%%% Project Spec

% \chapter*{Project Specification}
% \addcontentsline{toc}{chapter}{Project Specification}
% Your project specification goes here.

%%%%%%%%%%%%%%%%%%%%%%
%%% Timeline
\chapter{Timeline}

\chapter{Risks And Mitigations}

\section{Hardware Issues}

\begin{center}
    \begin{tabular}{l l  }
    Likelihood: & Low \\
    Importance: & High \\
    \end{tabular}
  \end{center}

Hardware failures, such as a lost or malfunctioning laptop, could disrupt the project's progress. Project data should be regularly backed up externally to reduce this risk. The project will be stored under Git with a GitHub remote repository. Under this arrangement, frequent code pushes upstream can minimise potential data loss. The report will be written on the Google Docs platform, providing cloud backup and version control. 


\section{Time Management Issues}

\begin{center}
    \begin{tabular}{l l  }
    Likelihood: & Moderate \\
    Importance: & Moderate \\
    \end{tabular}
  \end{center}

Underestimating the time required for tasks could result in missing milestones or goals. Perfect time estimates are impossible; however, tasks can subdivided appropriately to avoid significant surprises. Spreading out tasks evenly and leaving some buffer time can assist in avoiding work being cut short. 

\section{Machine Learning Risks}

\begin{center}
    \begin{tabular}{l l  }
    Likelihood: & Moderate \\
    Importance: & Low \\
    \end{tabular}
  \end{center}

Machine learning can be a slow and computationally expensive task; this risks slowing the development or failing to train an effective model. The Q-learning table's complexity and size can be gradually increased and dynamically controlled to avoid computational bottlenecks. Manual fine-tuning of the system can be timely. Instead, the hyperparameters will be optimised with grid search. 

\section{Software Development Challenges}

\begin{center}
    \begin{tabular}{l l  }
    Likelihood: & High \\
    Importance: & Moderate \\
    \end{tabular}
  \end{center}

Developing a complete graphical application can be complex, and unexpected software bugs may arise. Modern software engineering principles can minimise bugs and improve software quality. That is why this project will have version control, test-driven development, documentation, and static code analysis. 

\section{GUI Development Challenges}

\begin{center}
    \begin{tabular}{l l  }
    Likelihood: & Moderate \\
    Importance: & Low \\
    \end{tabular}
  \end{center}

Designing and implementing the Graphical User Interface may be more time-consuming or challenging than anticipated. This project will use GUI development libraries or frameworks that streamline the process. Start GUI development early in the project to allow for iterative improvements.

\section{Understanding of Reinforcement Concepts}

\begin{center}
    \begin{tabular}{l l  }
    Likelihood: & Moderate \\
    Importance: & High \\
    \end{tabular}
  \end{center}

Reinforcement learning has several abstract concepts, such as MDPs, Bellman equations, dynamic programming, or Q-learning, which may lead to incorrect implementations or interpretations. Referencing textbooks and research papers to check results can validate findings. Thoroughly studying reinforcement learning concepts can avoid misinterpretations.


%%%% ADD YOUR BIBLIOGRAPHY HERE
\newpage

\bibliographystyle{plain}
\bibliography{refrences}
\addcontentsline{toc}{chapter}{Bibliography}
\label{endpage}



\end{document}

\end{article}
